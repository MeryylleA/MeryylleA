<h1 align="center">Hi, I'm Francisco Antonio 👋</h1>
<h3 align="center">AI Architect & Researcher</h3>

<p align="center">
  <a href="https://www.linkedin.com/in/francisco-antonio-0434aa284/" target="_blank">
    <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn">
  </a>
  <a href="https://x.com/a93918" target="_blank">
    <img src="https://img.shields.io/badge/X (Twitter)-000000?style=for-the-badge&logo=x&logoColor=white" alt="X">
  </a>
  <a href="mailto:meryyllebr@gmail.com">
    <img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white" alt="Email">
  </a>
</p>

---

### 👨‍💻 About Me

I am a 17-year-old self-taught researcher passionate about building the next generation of language model architectures from the ground up. My work focuses on designing, implementing, and training high-performance AI systems in PyTorch that don't just work, but also teach us something new about learning itself.

- 🔭 I’m currently exploring **collaborative expert systems (MoC)** to unlock emergent reasoning in sparse models.
- 🌱 I believe that a deep, first-principles understanding of architecture is the key to building truly intelligent systems.
- 🚀 My goal is to contribute to a team that values creativity, initiative, and deep technical ambition.
- 📫 How to reach me: **meryyllebr@gmail.com**

---

### 🛠️ My Tech Stack

<p align="left">
  <a href="https://www.python.org" target="_blank"> 
    <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/python/python-original.svg" alt="python" width="40" height="40"/> 
  </a>
  <a href="https://pytorch.org/" target="_blank"> 
    <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/pytorch/pytorch-original.svg" alt="pytorch" width="40" height="40"/> 
  </a>
  <a href="https://git-scm.com/" target="_blank"> 
    <img src="https://www.vectorlogo.zone/logos/git-scm/git-scm-icon.svg" alt="git" width="40" height="40"/> 
  </a>
  <a href="https://www.docker.com/" target="_blank"> 
    <img src="https://raw.githubusercontent.com/devicons/devicon/master/icons/docker/docker-original-wordmark.svg" alt="docker" width="40" height="40"/> 
  </a>
</p>

*   **Core:** Python, PyTorch, Transformer Architecture Design
*   **Architectures:** Mixture-of-Experts (MoE), Sparse Attention (NSA), Grouped-Query Attention (GQA), RoPE, QK-Norm
*   **Training at Scale:** Distributed Data Parallel (DDP), Fully Sharded Data Parallel (FSDP)
*   **Tools:** Git, Docker, Weights & Biases

---

### ✨ Featured Projects

<p align="center">
  <!-- Lunaris Codex Card -->
  <a href="https://github.com/MeryylleA/lunariscodex">
    <img align="center" src="https://github-readme-stats.vercel.app/api/pin/?username=MeryylleA&repo=lunariscodex&theme=tokyonight&hide_border=true&icon_color=FF8C00&title_color=9370DB&text_color=E0E0E0" />
  </a>
  <br>
  <em>A powerful, modular LLM training toolkit featuring three experimental architectures: a SOTA Dense model, an industrial-grade Mixture-of-Experts (MoE), and a hybrid NSA-MoE for long-context research.</em>
  <br><br>
  <!-- Lunaris Codex MoC Card -->
  <a href="https://github.com/MeryylleA/lunariscodex-MoC">
    <img align="center" src="https://github-readme-stats.vercel.app/api/pin/?username=MeryylleA&repo=lunariscodex-MoC&theme=tokyonight&hide_border=true&icon_color=FF8C00&title_color=9370DB&text_color=E0E0E0" />
  </a>
  <br>
  <em>My primary research into a novel Mixture-of-Collaborative-Experts (MoC) architecture, designed to enable emergent reasoning and self-correction capabilities through a "2-Pass" communication mechanism.</em>
</p>

---

### 📊 My GitHub Stats

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=MeryylleA&show_icons=true&theme=tokyonight&hide_border=true&count_private=true" alt="MeryylleA's GitHub Stats" />
  <br>
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=MeryylleA&layout=compact&theme=tokyonight&hide_border=true" alt="MeryylleA's Top Languages" />
</p>
