<div align="center">
  <a href="https://git.io/typing-svg">
    <img src="https://readme-typing-svg.herokuapp.com?font=Fira+Code&weight=600&size=24&duration=3000&pause=1000&color=9370DB&center=true&vCenter=true&width=435&lines=AI+Architect+%26+Researcher;Building+LLMs+from+First+Principles;Exploring+Sparse+Architectures" alt="Typing SVG" />
  </a>

  <h1 align="center">Hi, I'm Francisco Antonio ğŸ‘‹</h1>

  <p align="center">
    <a href="https://www.linkedin.com/in/francisco-antonio-0434aa284/" target="_blank">
      <img src="https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn">
    </a>
    <a href="https://x.com/a93918" target="_blank">
      <img src="https://img.shields.io/badge/X_(Twitter)-000000?style=for-the-badge&logo=x&logoColor=white" alt="X">
    </a>
    <a href="mailto:meryyllebr@gmail.com">
      <img src="https://img.shields.io/badge/Email-D14836?style=for-the-badge&logo=gmail&logoColor=white" alt="Email">
    </a>
  </p>
</div>

---

### ğŸ‘¨â€ğŸ’» About Me

I am a **17-year-old AI Researcher** focused on designing and training high-performance language model architectures from the ground up. Unlike typical implementations, I build systems to understand the *why* behind learning dynamics.

My work centers on **deep learning optimization**, **distributed training**, and **experimental architectures**. I specialize in translating theoretical papers into efficient **PyTorch** implementations, pushing the boundaries of what sparse models can achieve.

* ğŸ”­ **Current Focus:** Developing **Collaborative Expert Systems (MoC)** to unlock emergent reasoning in sparse models.
* ğŸŒ± **Philosophy:** True intelligence comes from a deep, first-principles understanding of architecture.
* ğŸš€ **Goal:** To join a team that values technical rigor, creativity, and ambitious R&D.

---

### ğŸ› ï¸ Technical Arsenal

<div align="center">

| **Core Stack** | **Architectures & Research** | **Scale & Ops** |
|:---:|:---:|:---:|
| <img src="https://skillicons.dev/icons?i=python,pytorch" height="40"/> | **Transformer Design**<br>MoE, NSA, GQA, RoPE | <img src="https://skillicons.dev/icons?i=docker,git" height="40"/> |

</div>

<br>

* **Core:** Python, PyTorch, Custom Autograd Functions
* **Advanced Architectures:** Mixture-of-Experts (MoE), Sparse Attention (NSA), Grouped-Query Attention (GQA), QK-Norm
* **High-Performance Training:** Distributed Data Parallel (DDP), Fully Sharded Data Parallel (FSDP)
* **Tooling:** Weights & Biases (W&B), Docker, Git

---

### ğŸ§¬ Featured Research & Projects

<div align="center">

| **Lunaris Codex** | **Lunaris Codex MoC** |
|:---:|:---:|
| <a href="https://github.com/MeryylleA/lunariscodex"><img src="https://github-readme-stats.vercel.app/api/pin/?username=MeryylleA&repo=lunariscodex&theme=tokyonight&hide_border=true&icon_color=FF8C00&title_color=9370DB&text_color=E0E0E0" width="100%"/></a> | <a href="https://github.com/MeryylleA/lunariscodex-MoC"><img src="https://github-readme-stats.vercel.app/api/pin/?username=MeryylleA&repo=lunariscodex-MoC&theme=tokyonight&hide_border=true&icon_color=FF8C00&title_color=9370DB&text_color=E0E0E0" width="100%"/></a> |
| *Modular LLM training toolkit featuring SOTA Dense models and Hybrid NSA-MoE architectures.* | *Novel "Mixture-of-Collaborative-Experts" designed for emergent reasoning via 2-Pass communication.* |

</div>

---

### ğŸ“Š GitHub Analytics

<div align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=MeryylleA&show_icons=true&theme=tokyonight&hide_border=true&count_private=true" height="150" alt="stats" />
  <img src="https://github-readme-stats.vercel.app/api/top-langs/?username=MeryylleA&layout=compact&theme=tokyonight&hide_border=true" height="150" alt="languages" />
</div>

<br>

<div align="center">
  <a href="mailto:meryyllebr@gmail.com">
    <img src="https://img.shields.io/badge/Let's_Connect!-9370DB?style=for-the-badge" alt="Contact Me">
  </a>
</div>
